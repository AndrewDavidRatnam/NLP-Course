{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJADkRLgiiheZkqlFjF52a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndrewDavidRatnam/NLP-Course/blob/main/NLP_Summary_Series.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP LECTURE SUMMARY SERIES\n",
        "\n",
        "[Natural Language Processing, IIT Kharagpur](https://nptel.ac.in/courses/106105158)\n",
        "\n",
        "# ğŸ§  Natural Language Processing (NLP): A Comprehensive Overview\n",
        "\n",
        "---\n",
        "\n",
        "## 1. What is NLP?\n",
        "\n",
        "**Analogy:**  \n",
        "Think of NLP as a **multilingual chef in a bustling kitchen**. You place an order using slang or vague terms (\"something spicy\"), and the chef understands, translates, and serves a personalized dishâ€”whether itâ€™s a **response**, **summary**, or **action**.\n",
        "\n",
        "**Core Idea:**  \n",
        "NLP is a field of AI that enables computers to **process**, **understand**, and **generate** human language using linguistics, computer science, and machine learning.\n",
        "\n",
        "**Real-World Examples:**\n",
        "- **Chatbots:** \"Whereâ€™s my package?\" â†’ Understands & responds.\n",
        "- **Voice Assistants:** \"Play some jazz\" â†’ Interprets & plays music.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Key Components of NLP\n",
        "\n",
        "Each task in NLP is like a **tool in a chefâ€™s kitchen**:\n",
        "\n",
        "### a. Tokenization  \n",
        "**Analogy:** Like chopping vegetables into pieces.  \n",
        "**Function:** Breaks text into words, phrases, or symbols.\n",
        "\n",
        "**Example:**  \n",
        "Input: `\"best Italian restaurants near me\"`  \n",
        "Tokens: `[\"best\", \"Italian\", \"restaurants\", \"near\", \"me\"]`\n",
        "\n",
        "---\n",
        "\n",
        "### b. Part-of-Speech (POS) Tagging  \n",
        "**Analogy:** Labeling ingredients as \"protein,\" \"spice,\" etc.  \n",
        "**Function:** Identifies parts of speech: nouns, verbs, etc.\n",
        "\n",
        "**Example:**  \n",
        "\"She run fast\" â†’ Tags \"run\" as verb â†’ Suggests correction to \"runs\"\n",
        "\n",
        "---\n",
        "\n",
        "### c. Named Entity Recognition (NER)  \n",
        "**Analogy:** Tour guide highlighting landmarks.  \n",
        "**Function:** Detects names of people, places, and organizations.\n",
        "\n",
        "**Example:**  \n",
        "â€œElon Musk is CEO of Teslaâ€ â†’  \n",
        "- Person: Elon Musk  \n",
        "- Organization: Tesla\n",
        "\n",
        "---\n",
        "\n",
        "### d. Sentiment Analysis  \n",
        "**Analogy:** A critic gauging audience mood.  \n",
        "**Function:** Determines if a text is positive, negative, or neutral.\n",
        "\n",
        "**Example:**  \n",
        "Tweet: \"Love the new update!\" â†’ **Positive Sentiment**\n",
        "\n",
        "---\n",
        "\n",
        "### e. Machine Translation  \n",
        "**Analogy:** Real-time interpreter at a global conference.  \n",
        "**Function:** Translates text between languages, preserving meaning.\n",
        "\n",
        "**Example:**  \n",
        "\"Itâ€™s raining cats and dogs\" â†’  \n",
        "Translated to Spanish idiomatically: `\"EstÃ¡ lloviendo a cÃ¡ntaros\"`\n",
        "\n",
        "---\n",
        "\n",
        "## 3. How Does NLP Work?\n",
        "\n",
        "**Analogy:** NLP is like a child learning to talkâ€”starting with mimicry, then patterns, then context.\n",
        "\n",
        "### Core Process:\n",
        "1. **Input:** e.g., `\"Book a flight to Paris\"`\n",
        "2. **Preprocessing:** Tokenization, removing noise\n",
        "3. **Analysis:** Extracting meaning (e.g., \"Paris\" = location)\n",
        "4. **Output:** Response (e.g., show flight options)\n",
        "\n",
        "**Example:**  \n",
        "Autocomplete in email: `\"Looking forward to...\"` â†’ Predicts `\"our meeting\"`\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Why is NLP Challenging?\n",
        "\n",
        "**Analogy:** Human language is a flowing river with hidden currents (ambiguity, context, sarcasm).\n",
        "\n",
        "### Key Challenges:\n",
        "- **Ambiguity:** \"Bank\" = riverbank or financial institution?\n",
        "- **Cultural Nuances:** Sarcasm, idioms differ by region\n",
        "- **Bias in Data:** Leads to biased outputs\n",
        "\n",
        "**Example:**  \n",
        "Naive bot misreads sarcasm:  \n",
        "\"Great job, my package is lost again\" â†’ Interpreted as positive.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. NLP in Action Today\n",
        "\n",
        "**Analogy:** NLP is like a **Swiss Army knife**â€”versatile & everywhere.\n",
        "\n",
        "### Use Cases:\n",
        "- **Healthcare:** Flag symptoms in doctorâ€™s notes.\n",
        "- **Education:** Language apps like Duolingo.\n",
        "- **Entertainment:** Netflix analyzing reviews for recommendations.\n",
        "- **Security:** Detecting phishing via suspicious text patterns.\n",
        "\n",
        "**Example:**  \n",
        "E-commerce: NLP recommends scarves when you buy a coat.\n",
        "\n",
        "---\n",
        "\n",
        "## 6. The Future of NLP\n",
        "\n",
        "**Analogy:** If NLP today is a translator, tomorrow it will be a **mind-reader**â€”detecting tone, emotion, and intent.\n",
        "\n",
        "### Trends:\n",
        "- **Multimodal NLP:** Text + image + voice\n",
        "- **Low-Resource Languages:** Support for underrepresented languages\n",
        "- **Ethical NLP:** Fairness, bias reduction\n",
        "\n",
        "**Example:**  \n",
        "A future universal translator that interprets **tone**, **humor**, and **context** in real-time.\n",
        "\n",
        "---\n",
        "\n",
        "## âœ¨ Final Thoughts\n",
        "\n",
        "NLP is the art and science of making machines fluent in human languageâ€”like teaching a robot to join dinner conversation.\n",
        "\n",
        "From **search engines** to **summarization apps**, NLP **breaks down** language (like prepping ingredients) and **rebuilds** meaning (like serving a dish)â€”helping machines **understand us** as we understand each other.\n",
        "\n",
        "---\n",
        "\n",
        "## Want to Dive Deeper? ğŸ” STAY TUNED!!\n",
        "\n",
        "- How neural networks power modern chatbots  \n",
        "- Build a simple NLP model in Python  \n",
        "- Explore specific tasks like summarization, translation, or sentiment analysis\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fHzDZMEnEe38"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LECTURE 2 CODE AND SCRIPT IN YOUTUBE VIDEO AND ALSO ALL RELVANT INFORMATION INFORMATION"
      ],
      "metadata": {
        "id": "PENaWgBpFlsR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ¬ [YouTube Video Script: â€œWhy NLP is Hard: Translation Fails, Chatbot Chaos, and Real Winsâ€]\n",
        "[INTRO: 0:00 â€“ 0:25]\n",
        "\n",
        "ğŸµ [Light, quirky music]\n",
        "ğŸ¥ [Visuals: Funny translations, a confused chatbot, a tweet storm]\n",
        "\n",
        "Narrator (playful tone):\n",
        "\"Imagine saying â€œGoogle is awesomeâ€ and your translator responds withâ€¦ â€˜Google Bionicâ€™? ğŸ˜³ Yeah, that actually happened.\"\n",
        "\n",
        "ğŸ“Œ In this episode, we uncover why NLP â€” Natural Language Processing â€” is so hard, yet so powerful. From chatbot fails to translation blunders, and surprisingly successful tools you use every day.\n",
        "\n",
        "[SECTION 1: WHY NLP IS HARD | 0:25 â€“ 1:30]\n",
        "\n",
        "ğŸ¥ [Visuals: Split-screen of English vs. bad translations]\n",
        "\n",
        "Narrator:\n",
        "\"NLP isnâ€™t just about turning text into data â€” itâ€™s about understanding context. And context is... messy.\"\n",
        "\n",
        "ğŸ’¬ Take Google Translate:\n",
        "Say â€œGoogle is coolâ€ â€” but in Hindi, you get â€œGoogle champagne.â€ ğŸ¾ Why?\n",
        "Because â€˜coolâ€™ could mean trendyâ€¦ or coldâ€¦ or a drink apparently.\n",
        "\n",
        "ğŸ§  This is called Word Sense Disambiguation â€” and itâ€™s one of NLPâ€™s biggest challenges.\n",
        "\n",
        "[SECTION 2: EVEN HUMANS STRUGGLE | 1:30 â€“ 2:00]\n",
        "\n",
        "ğŸ¥ [Visuals: Ad blunders from global brands]\n",
        "\n",
        "Narrator:\n",
        "\"And guess what? Humans mess this up too.\"\n",
        "\n",
        "Pepsiâ€™s famous blunder in China?\n",
        "Their slogan â€œCome Alive with the Pepsi Generationâ€ got translated toâ€¦\n",
        "ğŸ‘‰ â€œPepsi brings your ancestors back from the dead.â€\n",
        "\n",
        "ğŸ“Œ So if humans struggle with context, how do we expect machines to do better?\n",
        "\n",
        "[SECTION 3: NLP GOALS â€“ AMBITION VS. REALITY | 2:00 â€“ 3:00]\n",
        "\n",
        "ğŸ¥ [Visuals: Microsoft Tay headlines, a chatbot gone wrong]\n",
        "\n",
        "Narrator:\n",
        "\"Thereâ€™s a huge gap between what we want NLP to do and what it can realistically do.\"\n",
        "\n",
        "ğŸŒ Ambitious Goal? A perfect, open-domain chatbot like Tay from Microsoft.\n",
        "ğŸ˜¬ Spoiler: It went rogue in less than 24 hours.\n",
        "\n",
        "âœ… Practical Goal? Tools that just work, like:\n",
        "\n",
        "Query correction: â€œwold cupâ€ â†’ â€œworld cupâ€\n",
        "\n",
        "Query completion: Predicting â€œhow to train yourâ€¦â€ â†’ â€œdragonâ€\n",
        "\n",
        "ğŸ“Œ Simple, useful, reliable â€” thatâ€™s the current sweet spot for NLP.\n",
        "\n",
        "[SECTION 4: REAL-WORLD WINS | 3:00 â€“ 4:15]\n",
        "\n",
        "ğŸ¥ [Visuals: News articles, code snippets, chatbot interfaces]\n",
        "\n",
        "Narrator:\n",
        "\"Letâ€™s talk about whatâ€™s working.\"\n",
        "\n",
        "ğŸ“° Information Extraction\n",
        "From a sentence like:\n",
        "â€œJane Doe, President of Acme Corp, resigned todayâ€¦â€\n",
        "NLP can pull out:\n",
        "\n",
        "Name: Jane Doe\n",
        "\n",
        "Role: President\n",
        "\n",
        "Company: Acme Corp\n",
        "\n",
        "ğŸ¤– Domain-specific Chatbots\n",
        "A course assistant bot that answers student queries with 97% accuracy? Thatâ€™s real. Thatâ€™s useful.\n",
        "Unlike Tay.\n",
        "\n",
        "ğŸ¦ Sentiment Analysis\n",
        "By analyzing tweets, NLP can predict election outcomes, track public mood, or detect market trends.\n",
        "\n",
        "ğŸ“¬ Spam Detection\n",
        "Gmail uses NLP to filter spam â€” so you donâ€™t have to.\n",
        "\n",
        "ğŸ“„ Text Summarization\n",
        "Apps like Inshorts condense long news into short summaries â€” using NLP.\n",
        "\n",
        "[SECTION 5: NLP IN ACTION (LIVE DEMO!) | 4:15 â€“ 5:15]\n",
        "\n",
        "ğŸ¥ [Screen recording of Python code running]\n",
        "\n",
        "Narrator:\n",
        "\"Want a peek under the hood? Hereâ€™s a basic NLP demo using Python.\"\n",
        "\n",
        "python\n",
        "Copy\n",
        "Edit\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "text = \"Google is awesome but translation needs work!\"\n",
        "tokens = word_tokenize(text)\n",
        "print(\"Tokens:\", tokens)\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "scores = sid.polarity_scores(text)\n",
        "print(\"Sentiment Scores:\", scores)\n",
        "ğŸ§ª We tokenize the text and analyze its sentiment. The result? Positive vibes with a hint of criticism â€” just like real feedback.\n",
        "\n",
        "[SECTION 6: PRACTICALITY OVER PERFECTION | 5:15 â€“ 6:00]\n",
        "\n",
        "ğŸ¥ [Visuals: Tools that â€œmostlyâ€ work â€” Gmail, search, summaries]\n",
        "\n",
        "Narrator:\n",
        "\"Perfect NLP doesnâ€™t exist. But â€˜good enoughâ€™ NLP? That powers our digital world.\"\n",
        "\n",
        "ğŸ“Œ Translation may be flawed, but we still use it.\n",
        "ğŸ“Œ Chatbots arenâ€™t perfect, but they save time.\n",
        "ğŸ“Œ NLP isnâ€™t magic â€” itâ€™s clever algorithms, smart design, and lots of data.\n",
        "\n",
        "ğŸ‘¨â€ğŸ« And thatâ€™s what this course teaches â€” not just how to use NLP, but how to build it, improve it, and make it useful.\n",
        "\n",
        "[OUTRO: 6:00 â€“ 6:30]\n",
        "\n",
        "ğŸµ [Inspiring outro music]\n",
        "ğŸ¥ [Montage of successful NLP tools, ending on a student building one]\n",
        "\n",
        "Narrator (motivational):\n",
        "\"NLP is hard â€” but not impossible. Start with what works. Build toward whatâ€™s better.\"\n",
        "\n",
        "ğŸ‘ Like this video if youâ€™ve ever laughed at a bad translation. Subscribe for more deep dives into the future of language and AI.\n",
        "\n",
        "ğŸ“˜ Next up: Why algorithms matter â€” and how they power NLP."
      ],
      "metadata": {
        "id": "lXalAWBjF3DQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Lecture 2: What Do We Do in NLP?\n",
        "####Summary:\n",
        "\n",
        "Lecture 2 introduces the practical tasks NLP practitioners undertake, building on Lecture 1â€™s overview by illustrating the engineering goal of building systems for real-world use. The instructor uses translation errors, like Google Translate rendering â€œGoogle is awesomeâ€ as â€œGoogle Bionicâ€ in Hindi, to highlight NLPâ€™s imperfections and challenges, such as word sense disambiguation. Human translation blunders, like Pepsiâ€™s slogan becoming â€œPepsi brings your relatives back from the deadâ€ in Chinese, show that even humans struggle with context, underscoring NLPâ€™s complexity. The lecture contrasts ambitious goals, like perfect translation or open-domain chatbots (e.g., Microsoftâ€™s failed Tay), with achievable ones, like query correction in search engines. Practical applications are emphasized, including information extraction to structure data from news reports, such as identifying a personâ€™s role in a company. Domain-specific chatbots, like a course TA bot answering student queries with 97% accuracy, are presented as feasible NLP successes. Sentiment analysis is introduced as a tool to gauge opinions from social media, exemplified by studies predicting election outcomes. Other tasks, like spam detection and text summarization, are noted as widely used in daily life, from email filters to news apps. The instructor stresses that while NLP systems arenâ€™t perfect, theyâ€™re â€œgood enoughâ€ for many applications, encouraging students to design innovative solutions. The lecture sets the stage for future discussions on why NLP is hard, promising deeper dives into algorithms and challenges.\n",
        "\n",
        "####Key Concepts:\n",
        "\n",
        "Engineering Goal: Designing systems to process natural language for practical applications.\n",
        "Translation Challenges: Imperfect translations (e.g., â€œGoogle is awesomeâ€ â†’ â€œGoogle Bionicâ€) due to context errors.\n",
        "Word Sense Disambiguation: Resolving multiple meanings of words (e.g., â€œcoolâ€ as trendy vs. cold).\n",
        "Human Errors: Translation blunders (e.g., Pepsiâ€™s slogan) show context is hard for humans too.\n",
        "Ambitious Goals: Perfect translation or open-domain chatbots (e.g., Tayâ€™s failure) remain elusive.\n",
        "Query Correction: Fixing misspellings in search queries (e.g., â€œwoldâ€ â†’ â€œworldâ€).\n",
        "Query Completion: Predicting full queries from partial inputs using language modeling.\n",
        "Information Extraction: Structuring unstructured text, like extracting job titles from news (e.g., â€œpresident, Times newspaperâ€).\n",
        "Domain-Specific Chatbots: Limited-scope bots (e.g., course TA bot) achieve high accuracy.\n",
        "Sentiment Analysis: Classifying opinions from social media to predict trends (e.g., election outcomes).\n",
        "Spam Detection: Filtering unwanted emails or comments via text analysis.\n",
        "Text Summarization: Condensing articles into key points for news or research.\n",
        "Practicality Over Perfection: NLP systems are imperfect but useful for many tasks.\n",
        "Algorithm Design: Solving NLP problems requires efficient, tailored algorithms.\n",
        "Real-World Examples:\n",
        "\n",
        "Google Translate: Struggles with phrases like â€œGoogle is coolâ€ (translated as â€œGoogle champagneâ€), showing the need for better disambiguation.\n",
        "Search Engines (Google): Corrects â€œwold cupâ€ to â€œworld cupâ€ and predicts query completions for faster searches.\n",
        "News Analysis: Extracts structured data (e.g., â€œJohn is CEO of Acmeâ€) from articles for databases.\n",
        "Course Chatbot: A TA bot answers student queries with 97% accuracy, showing domain-specific success.\n",
        "Election Sentiment (Twitter): Analyzes tweets to predict voter preferences, as seen in presidential campaigns.\n",
        "Gmail Spam Filter: Detects spam emails by analyzing text patterns, keeping inboxes clean.\n",
        "\n",
        "###Explaining the Concept: What Do We Do in NLP?\n",
        "\n",
        "####Analogy:\n",
        "\n",
        "Imagine NLP practitioners as detectives sifting through a noisy crime sceneâ€”text data scattered across emails, tweets, and articles. Their job is to collect clues (tokenize words), identify key players (extract entities), and piece together the story (summarize or classify sentiment), all while knowing the evidence isnâ€™t perfect. Like detectives using magnifying glasses (algorithms), they clean up smudges (preprocessing) to spot patterns, such as a suspectâ€™s alias having multiple meanings (disambiguation). They might correct a witnessâ€™s typo (query correction) or predict what someoneâ€™s hiding based on partial clues (query completion). Sometimes, they build a case file (structured data) from chaotic notes, like linking a name to a job title. Other times, they gauge the crowdâ€™s mood (sentiment analysis) to sense tension. Their tools, like fingerprint kits (NLTK, spaCy), help crack cases, but mistakesâ€”like misreading â€œcoolâ€ as â€œchampagneâ€â€”remind them context is tricky. Unlike fictional sleuths solving perfect mysteries, NLP detectives deliver â€œgood enoughâ€ reports (applications) that help real people, from filtering spam to translating news. They donâ€™t aim for flawless truth but for practical insights, like a chatbot calming a customer or a summary saving time. Each task, from cleaning to analyzing, is a step toward making sense of the worldâ€™s messy language.\n",
        "\n",
        "####Detailed Explanation with Analogies:\n",
        "\n",
        "Text as a Crime Scene: Raw text is chaotic, like evidence strewn about. NLP practitioners tokenize it (collect clues into words) and clean it (remove noise like punctuation), setting the stage for analysis, as seen in the lectureâ€™s translation examples needing preprocessing.\n",
        "Disambiguation as a Suspect Lineup: Words like â€œcoolâ€ have multiple identities (trendy, cold). Practitioners pick the right one using context, just as the lecture notes Google Translateâ€™s errors stem from picking wrong senses.\n",
        "Extraction as Filing Reports: Information extraction organizes messy text into neat records, like a detective noting â€œJohn, CEO, Acmeâ€ from a rambling article, mirroring the lectureâ€™s example of structuring news data.\n",
        "Sentiment as Reading the Room: Practitioners classify textâ€™s vibeâ€”positive, negativeâ€”like detectives sensing a crowdâ€™s mood. The lectureâ€™s election analysis shows this, predicting outcomes from tweets.\n",
        "Chatbots as Assistants: Domain-specific chatbots, like the course TA bot, are junior detectives trained for one case (a course), answering reliably, unlike open-domain bots (Tay) that go rogue, as the lecture contrasts.\n",
        "####Real-World Examples:\n",
        "\n",
        "Customer Service (Amazon): Chatbots use tokenization and entity recognition to parse â€œWhereâ€™s my package?â€ and fetch tracking details, streamlining support.\n",
        "YouTube Moderation: Spam detection flags toxic comments by analyzing patterns, keeping platforms safe, as hinted in the lectureâ€™s spam discussion.\n",
        "News Apps (BBC): Text summarization condenses articles into headlines, using extraction to highlight key events, aligning with the lectureâ€™s practical goals.\n",
        "Bing Search: Query completion suggests â€œWorld Cup 2022â€ when typing â€œWorld C,â€ leveraging language modeling, as the lecture describes.\n",
        "Marketing Analytics: Sentiment analysis scans reviews to gauge product reception, guiding campaigns, like the lectureâ€™s social media example.\n",
        "####Connection to Prior Lessons:\n",
        "Lecture 1 outlined NLPâ€™s dual goalsâ€”scientific (understanding language) and engineering (building tools)â€”and promised applications like summarization and opinion mining. Lecture 2 delivers by showing what practitioners do to achieve the engineering goal, using examples like query correction and chatbots. The detective analogy extends Lecture 1â€™s view of text as abundant but messy, requiring practical steps (e.g., Lecture 1â€™s tokenization) to solve real problems. The lectureâ€™s focus on imperfect but useful systems echoes Lecture 1â€™s engineering emphasis, grounding promised topics in tangible tasks.\n"
      ],
      "metadata": {
        "id": "ON-DRr__F565"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CODE EXAMPLE 1 SENTIMENT ANALYSIS"
      ],
      "metadata": {
        "id": "7QGdg_BrIS6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a84UCqRnHR_s",
        "outputId": "9cf454e6-45bb-4591-e1ba-2ebe90fc3300"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Google is awesome but translation needs work\"\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "print(\"Tokens:\", tokens)\n",
        "print(\"\")\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "scores = sid.polarity_scores(text)\n",
        "print(\"Sentiment Scores:\", scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rd6SKfjWIPeK",
        "outputId": "fe78bf26-a646-4274-8fc0-1af0d7a2f7bd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['Google', 'is', 'awesome', 'but', 'translation', 'needs', 'work']\n",
            "\n",
            "Sentiment Scores: {'neg': 0.0, 'neu': 0.702, 'pos': 0.298, 'compound': 0.3716}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### CODE EXAMPLE : QUERY COMPLETION"
      ],
      "metadata": {
        "id": "lL7yqHyqIYOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from difflib import get_close_matches"
      ],
      "metadata": {
        "id": "6x1eno2zIZxG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dictonary = [\"world\", \"cup\", \"football\", \"2024\"]\n",
        "\n",
        "mispelled_query = \"wold cup\"\n",
        "\n",
        "words = mispelled_query.split()\n",
        "words\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYzlu0_LIhIm",
        "outputId": "59a642f6-558d-4de4-dbbe-86194338753c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wold', 'cup']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corrected_query = []\n",
        "for word in words:\n",
        "  corrected_query.append(get_close_matches(word, dictonary)[0])\n",
        "corrected_query = \" \".join(corrected_query)\n",
        "print(f\"Did you mean: {corrected_query} ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7yM7CJnIuwg",
        "outputId": "eb27506d-9b67-4988-e551-cd509fc4fdc5"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did you mean: world cup ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# s\n"
      ],
      "metadata": {
        "id": "JzWKqTMjcgbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 3: Why is NLP hard  <br>\n",
        "CODE AND SCRIPT IN YOUTUBE VIDEO AND ALSO ALL RELVANT INFORMATION INFORMATION LIKE CHATGPT SUMMARIZATION ETC"
      ],
      "metadata": {
        "id": "8I6rIxWccho7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QBq56yxGcxRR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}